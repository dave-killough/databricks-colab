{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMOuSp0FverxUJYDWbZC5S1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dave-killough/databricks-colab/blob/main/PySpark%2C_Parquet%2C_Delta%2C_and_SQL_on_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "Nq9ZmPhqmSqa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9d0zNVuXBZr"
      },
      "outputs": [],
      "source": [
        "%pip install pyspark==3.5.0 delta-spark==3.0.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pyspark.sql import SparkSession\n",
        "from delta import *\n",
        "import pyspark.sql\n",
        "import os\n",
        "import shutil"
      ],
      "metadata": {
        "id": "h58eSNulkTOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instantiate Spark and Delta"
      ],
      "metadata": {
        "id": "vpTrxR1-mZct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "builder = SparkSession.builder.appName(\"eo-master-file\"\n",
        "    ).config(\"spark.sql.extensions\",\n",
        "             \"io.delta.sql.DeltaSparkSessionExtension\"\n",
        "    ).config(\"spark.sql.catalog.spark_catalog\",\n",
        "             \"org.apache.spark.sql.delta.catalog.DeltaCatalog\"\n",
        "    ).config(\"spark.jars.packages\", \"delta-spark:3.0.0\")\n",
        "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
        "# version that Databricks will use\n",
        "#spark = SparkSession.builder.appName(\"eo-master-file\").getOrCreate()"
      ],
      "metadata": {
        "id": "d-nKC9i0hxZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Schema"
      ],
      "metadata": {
        "id": "oRHSjpB3mhle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IRS Exempt Organization Master File\n",
        "# https://www.irs.gov/pub/irs-soi/eo_info.pdf\n",
        "from pyspark.sql.types import StructType\n",
        "from pyspark.sql.types import StructField\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql.types import LongType\n",
        "schema = StructType([\n",
        "    StructField(\"EIN\", StringType(), True),\n",
        "    StructField(\"NAME\", StringType(), True),\n",
        "    StructField(\"ICO\", StringType(), True),\n",
        "    StructField(\"STREET\", StringType(), True),\n",
        "    StructField(\"CITY\", StringType(), True),\n",
        "    StructField(\"STATE\", StringType(), True),\n",
        "    StructField(\"ZIP\", StringType(), True),\n",
        "    StructField(\"RULING\", StringType(), True),\n",
        "    StructField(\"TAX_PERIOD\", StringType(), True),\n",
        "    StructField(\"GROUP\", StringType(), True),\n",
        "    StructField(\"SUBSECTION\", StringType(), True),\n",
        "    StructField(\"AFFILIATION\", StringType(), True),\n",
        "    StructField(\"CLASSIFICATION\", StringType(), True),\n",
        "    StructField(\"DEDUCTIBILITY\", StringType(), True),\n",
        "    StructField(\"FOUNDATION\", StringType(), True),\n",
        "    StructField(\"ACTIVITY\", StringType(), True),\n",
        "    StructField(\"ORGANIZATION\", StringType(), True),\n",
        "    StructField(\"STATUS\", StringType(), True),\n",
        "    StructField(\"ASSET_CD\", StringType(), True),\n",
        "    StructField(\"INCOME_CD\", StringType(), True),\n",
        "    StructField(\"FILING_REQ_CD\", StringType(), True),\n",
        "    StructField(\"PF_FILING_REQ_CD\", StringType(), True),\n",
        "    StructField(\"ACCT_PD\", StringType(), True),\n",
        "    StructField(\"ASSET_AMT\", LongType(), True),\n",
        "    StructField(\"INCOME_AMT\", LongType(), True),\n",
        "    StructField(\"REVENUE_AMT\", LongType(), True),\n",
        "    StructField(\"NTEE_CD\", StringType(), True),\n",
        "    StructField(\"SORT_NAME\", StringType(), True)\n",
        "])"
      ],
      "metadata": {
        "id": "mvr8obmIdcIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PySpark\n",
        "https://spark.apache.org/docs/latest/api/python/index.html"
      ],
      "metadata": {
        "id": "E7RppGpEmqL3"
      }
    },
    {
      "source": [
        "# ingest an example file\n",
        "for eon in ['eo1','eo2','eo3','eo4']:\n",
        "    response = requests.get(\n",
        "        f\"https://www.irs.gov/pub/irs-soi/{eon}.csv\")\n",
        "    with open(f\"{eon}.csv\", \"wb\") as f:\n",
        "        f.write(response.content)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "OfB0HizEaHz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read from local csv file to spark dataframe\n",
        "spark_csv_df = spark.read.csv(\n",
        "    \"eo[1234].csv\",schema=schema, header=True)"
      ],
      "metadata": {
        "id": "m1MUtAaokzYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display first 3 rows using pyspark\n",
        "spark_csv_df.show(3)"
      ],
      "metadata": {
        "id": "203RWQIbk9l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display first 3 rows using pandas\n",
        "spark_csv_df.limit(3).toPandas() # prettier display"
      ],
      "metadata": {
        "id": "lWBYrJNKdvyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parquet\n",
        "https://parquet.apache.org/"
      ],
      "metadata": {
        "id": "So9pSlWmnEtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transform to parquet - creates a directory\n",
        "spark_csv_df.write.format(\"parquet\"\n",
        "    ).mode(\"overwrite\").save(\"eo_parquet\")"
      ],
      "metadata": {
        "id": "SkUYry2xkS1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read delta table to dataframe\n",
        "spark_parquet_df = spark.read.format(\"parquet\"\n",
        "    ).load(\"eo_parquet\")\n",
        "# display first 3 rows using pandas\n",
        "spark_parquet_df.limit(3).toPandas()"
      ],
      "metadata": {
        "id": "hsQko6gNnQ6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform to SQL\n",
        "spark_parquet_df.createOrReplaceTempView('eo_parquet')\n",
        "spark.sql(\"\"\"\n",
        "    SELECT NAME, CITY, STATE, ASSET_AMT\n",
        "    FROM eo_parquet\n",
        "    ORDER BY ASSET_AMT DESC LIMIT(20)\n",
        "\"\"\").toPandas()"
      ],
      "metadata": {
        "id": "ec31Ell69Uq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Delta\n",
        "https://delta.io/"
      ],
      "metadata": {
        "id": "ifKr2ijFnW1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transform to delta - creates a directory\n",
        "if os.path.exists('eo_delta'):\n",
        "    # overwrites cause growwwwwwth, so clear before\n",
        "    if spark.catalog._jcatalog.tableExists(\"eo_delta\"):\n",
        "        spark.catalog.dropTempView(\"eo_delta\")\n",
        "    shutil.rmtree('eo_delta')\n",
        "spark_csv_df.write.format(\"delta\").save(\"eo_delta\")"
      ],
      "metadata": {
        "id": "H30OCBn2hUGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read delta table to dataframe\n",
        "spark_delta_df = spark.read.format(\"delta\").load(\"eo_delta\")\n",
        "spark_delta_df.limit(3).toPandas()"
      ],
      "metadata": {
        "id": "_ExTJdIIlhSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform to SQL\n",
        "spark_parquet_df.createOrReplaceTempView('eo_delta')\n",
        "spark.sql(\"\"\"\n",
        "    SELECT NAME, CITY, STATE, ASSET_AMT\n",
        "    FROM eo_delta\n",
        "    ORDER BY ASSET_AMT DESC LIMIT(5)\n",
        "\"\"\").toPandas()"
      ],
      "metadata": {
        "id": "8s-4A0MFHSNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SQL"
      ],
      "metadata": {
        "id": "um-85UIQziCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SHOW TABLES\").show()"
      ],
      "metadata": {
        "id": "7-ALF7pr-FCT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}